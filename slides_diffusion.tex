\documentclass{beamer}  
  
% Theme choice:  
\usetheme{Madrid}  


% Packages for mathematics  
\usepackage{amsmath}  
\usepackage{amsfonts}  
\usepackage{amssymb}  
\usepackage{CJKutf8}
\newenvironment<>{proofs}[1][\proofname]{%
    \par
    \def\insertproofname{#1.}%
    \usebeamertemplate{proof begin}#2}
  {\usebeamertemplate{proof end}}
\makeatother

% Title page details:   
\title[Understanding diffusion model]{Deep Dive: Understanding diffusion model from a mathematical view}  
\author{Pipi Hu}  
\institute[MSR AI4S]{Microsoft Research AI4Science}  
\date{\today}  

\pgfdeclareimage[width=2cm]{logo}{ai4s.png}
\logo{\pgfuseimage{logo}{\vspace{-6pt}}}

% Outline slide  
% \begin{frame}{Outline}  
%   \tableofcontents  
% \end{frame}  

\setbeamertemplate{navigation symbols}{}
\AtBeginSection[]  
{  
    \begin{frame}<beamer>{Outline}         
        \tableofcontents[currentsection]  
    \end{frame}  
}  
  
\AtBeginSubsection[]  
{  
    \begin{frame}<beamer>{Outline}         
        \tableofcontents[currentsubsection]  
    \end{frame}  
}  

% \setbeamertemplate{navigation symbols}{}
% \AtBeginSection[]
% {
%     \begin{frame}<beamer>{Outline}       \tableofcontents[currentsection]
%     \end{frame}
% }

\begin{document}  
  
% Title slide  
\begin{frame}  
  \titlepage  
\end{frame}  

\begin{frame}{Feynman's words}
\centering
    What I cannot create, I do not understand.
\end{frame}
  
% Presentation slides  
% \section{Molecular dynamics}  


\section{Preliminary: Generating Samples from Probability Distributions}

\begin{frame}{Generate samples form given distribution}
Given a distribution $p(x)$, how to sample from the distribution?
\begin{itemize}
    \item Uniform distribution \& Gaussian distribution: easy sampling 
    \item Mixture Gaussian: determine which Gaussian to sample \& sample from that Gaussian
    \item A general sample function?
    \begin{itemize}
        \item \textcolor{red}{Langevin Markov Chain Monte Carlo sampling (Langevin MCMC)}
        \item Stein Variational Gradient Descent (SVGD)
        \item ...
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Score function is all you need?}
A typical process of generating new samples from modeling the data distribution
    \begin{enumerate}
        \item To find the probability function $p(x)$, model $p(x;\theta)$.
        \item Normalization distribution $p(x;\theta)=\frac{1}{C(\theta)}e^{-E(x;\theta)}$ with $C(\theta)\equiv\int_x e^{-E(x;\theta)}dx$.
        \item Generating samples from above sampling methods.
    \end{enumerate}
Recall the Langevin Markov Chain Monte Carlo sampling
\begin{equation}
    x_t = x_{t-1}+\frac{\Delta t}{2}\textcolor{red}{\nabla_x\log p(x_{t-1};\theta)}+\sqrt{\Delta t}\epsilon, \quad \epsilon\sim N(0, 1).
\end{equation}
Here $\textcolor{red}{\nabla_x\log p(x_{t-1};\theta)}=-\nabla_xE(x;\theta)$ is free of the normalization $C(\theta)$.

Define the score function
\begin{equation}
    S(x;\theta) \equiv \textcolor{red}{\nabla \log p(x;\theta)}.
\end{equation}
\end{frame}

\begin{frame}{More about Langevin MCMC and the score function}
Continuous form of the Langevin MCMC
\begin{itemize}
    \item $\Delta t\to 0$
    \begin{equation}
        dx = \frac{1}{2}\nabla_x\log p(x) dt+ dB_t,
    \end{equation}
    where $dB_t$ is a Brownian motion.
    \item Given $p(x)=\frac{1}{C}e^{-E}$, we have 
    \begin{equation}
        dx = -\frac{1}{2}\textcolor{red}{\nabla_x E}dt + dB_t
    \end{equation}
\end{itemize}
Langevin MCMC is  overdamped Langevin dynamics
\begin{itemize}
    \item Langevin dynamics (MD)
    \begin{equation}
        \ddot{x} = -\nabla_x E - \gamma \dot{x} + dB_t,
    \end{equation}
    \item Given $\gamma \dot{x}
    \gg \ddot{x}$, we have the overdamped Langevin equation 
    \begin{equation}
        dx = -\frac{1}{\gamma}\nabla_x E + \frac{1}{\gamma}dB_t.
    \end{equation}
\end{itemize}
\end{frame}

\section{Matching score for training}
\begin{frame}{Matching the score by neural networks}
Recall the definition 
\begin{equation}
    S \equiv \nabla_x\log p(x),
\end{equation}
The key is to matching the score by a neural network
\begin{equation}
    J_{ESM} =\frac{1}{2} \mathbb{E}_p\left[\|s(x;\theta)-\frac{\partial \log p(x)}{\partial x}\|^2\right],
\end{equation}
where $J_{ESM}$ is called Explicit Score Matching loss. However, it is not tractable to compute $\frac{\partial \log p(x)}{\partial x}$ from data.\\[1em]

Where should we go?
\end{frame}

\begin{frame}{Implicit Score Matching (ISM) loss}
Implicit Score Matching loss (Aapo, 2005) was developed to make a tractable score matching 
\begin{equation}
    J_{ISM} \equiv \mathbb{E}_p\left[\frac{1}{2}\|s(x;\theta)\|^2+\nabla\cdot s(x;\theta)\right]=J_{ESM}-C.
\end{equation}
\begin{proof}
    \begin{equation}
    \begin{aligned}
    J_{ESM}&=\frac{1}{2} \mathbb{E}_p\left[\|s(x;\theta)-\frac{\partial \log p(x)}{\partial x}\|^2\right]\\
        & = \frac{1}{2} \mathbb{E}_p\left[\|s\|^2\right]- \mathbb{E}_p[s\cdot\frac{\partial \log p}{\partial x}] + \frac{1}{2}\mathbb{E}_p\left[\|\frac{\partial \log p}{\partial x}\|^2\right]
    \end{aligned}
    \end{equation}
    where 
    \begin{equation}
    \scriptsize
    \begin{aligned}
        &-  \mathbb{E}_p[s\cdot\frac{\partial \log p}{\partial x}] =-\int_x ps\cdot \nabla \log p dx
        = -\int_x ps\cdot \frac{\nabla p}{p}dx\\ 
        &=-\int_x s\cdot \nabla pdx = -\int \nabla\cdot(ps)dx + \int p\nabla\cdot sdx=\mathbb{E}_p[\nabla\cdot s].
    \end{aligned}
    \end{equation}
So we have 
$
    J_{ISM}= J_{ESM}-C,
$ where $C \equiv \frac{1}{2}\mathbb{E}_p\left[\|\frac{\partial \log p}{\partial x}\|^2\right]$.
\end{proof}
\end{frame}

\begin{frame}{Denoising Score Matching (DSM) loss}
However, the ISM score is not very stable to optimize, with two reasons
\begin{enumerate}
    \item Expectation is performed on the whole distribution;
    \item The loss is negative decreasing to $-C$ with a great quantity, e.g. $-1e5$.
\end{enumerate}

Denoising Score Matching (DSM) loss (Vincent, 2011) is developed to solve this problem
\begin{equation}
    J_{DSM} = \frac{1}{2}\mathbb{E}_{p(x,\Tilde{x})}\left[\|s(\Tilde{x};\theta)-\nabla_{\Tilde{x}}\log p(\Tilde{x}|x)\|^2\right].
\end{equation}
And we can prove that $J_{DSM} = J_{ESM}+C$.
\end{frame}

\begin{frame}{Prove the equivalence $J_{DSM} = J_{ESM}+C$}
\begin{proof}
We expand the formula and check the items one by one.\\[-1.5em]
\begin{equation}
    \scriptsize
    \begin{aligned}
      J_{DSM} &\equiv \frac{1}{2}\mathbb{E}_{p(x,\Tilde{x})}\left[\|s(\Tilde{x};\theta)-\nabla_{\Tilde{x}}\log p(\Tilde{x}|x)\|^2\right]\\
      &=\frac{1}{2}\mathbb{E}_{p(\Tilde{x})}\left[\|s(\Tilde{x})\|^2\right]-\mathbb{E}_{p(x,\Tilde{x})}[s(\Tilde{x})\cdot\nabla_{\Tilde{x}}\log p(\Tilde{x}|x)]+\frac{1}{2}\mathbb{E}_{p(x,\Tilde{x})}[\|\nabla_{\Tilde{x}}\log p(\Tilde{x}|x)\|^2]  
    \end{aligned}
\end{equation}
And we can prove that the cross term of $J_{ESM}$ and $J_{DSM}$ is equal.\\[-1em]
\begin{equation}
\scriptsize
\begin{aligned}
&\mathbb{E}_p(\Tilde{x})[s(\Tilde{x})\cdot\nabla_{\Tilde{x}}\log p(\Tilde{x})]
 = \int_{\Tilde{x}} p(\Tilde{x})s(\Tilde{x})\cdot\nabla_{\Tilde{x}}\log p(\Tilde{x})d\Tilde{x}\\
 &= \int_{\Tilde{x}} s(\Tilde{x})\cdot\nabla_{\Tilde{x}} p(\Tilde{x})d\Tilde{x}
 = \int_{\Tilde{x}}\int_x p(x)s(\Tilde{x})\cdot\nabla_{\Tilde{x}} p(\Tilde{x}|x)d\Tilde{x}dx\\
& = \int_{\Tilde{x}}\int_x p(\Tilde{x}|x)p(x)s(\Tilde{x})\cdot\nabla_{\Tilde{x}} \log p(\Tilde{x}|x)d\Tilde{x}dx
= \mathbb{E}_{p(\Tilde{x},x)}\left[s(\Tilde{x})\cdot\nabla_{\Tilde{x}} \log p(\Tilde{x}|x)\right].
\end{aligned}
\end{equation}
Finally we have \\[-1em]
\begin{equation}
\scriptsize
    J_{DSM} = J_{ESM} -\frac{1}{2}\mathbb{E}_p\left[\|\nabla_{\Tilde{x}} \log p(\Tilde{x})\|^2\right] + \frac{1}{2}\mathbb{E}_{p(x,\Tilde{x})}[\|\nabla_{\Tilde{x}}\log p(\Tilde{x}|x)\|^2].
\end{equation}
\end{proof}
\end{frame}

\begin{frame}{DSM is all you need?}
Problem arises when $\Tilde{x}\to x$. 
We can prove that when Gaussian noised added by  $p(\Tilde{x}|x) = N(\alpha x, \sigma^2)$, 
\begin{equation}
    J_{DSM}\to \infty, \text{ if } \Tilde{x}\to x.
\end{equation}
\begin{proof}
  Given the Gaussian noise added, we have \\[-1em] 
  \begin{equation}
  \scriptsize
\nabla_{\Tilde{x}}\log p(\Tilde{x}|x) = \nabla_{\Tilde{x}}\log e^{-\frac{(\Tilde{x}-\alpha x)^2}{2\sigma^2}} = -\frac{\Tilde{x}-\alpha x}{\sigma^2}.
  \end{equation}  
And we can show that the following formula goes to infinity\\[-1em]
\begin{equation}
\scriptsize
\begin{aligned}
&\mathbb{E}_{p(x,\Tilde{x})}[\|\nabla_{\Tilde{x}}\log p(\Tilde{x}|x)\|^2] 
=\mathbb{E}_{p(x,\Tilde{x})}[\|\frac{\Tilde{x}-\alpha x}{\sigma^2}\|^2]\\
&=\mathbb{E}_{p(x)}\mathbb{E}_{p(\Tilde{x}|x)}[\|\frac{\Tilde{x}-\alpha x}{\sigma^2}\|^2]
=\mathbb{E}_{\epsilon\sim N(0,1)}[\|\frac{\epsilon}{\sigma}\|^2] \to \infty \text{ if } \sigma\to 0.
\end{aligned}
\end{equation}
Finally, we know that\\[-1em]
\begin{equation}
\scriptsize
    J_{DSM} = J_{ESM}+C \to \infty \text{ as } C\to \infty \text{ when } \Tilde{x}\to x.
\end{equation}
\end{proof}  
\end{frame}

\section{Relations of different models: $x_0$, $\epsilon$ and score model.}

\begin{frame}{Revisit the adding noise from $x$ to $\Tilde{x}$}
Gaussian transition kernel for adding noise from $x$ to $\Tilde{x}$
\begin{equation}
    \Tilde{x} = \alpha x + \sigma \epsilon,
\end{equation}
which equivalent to the Gaussian transition kernel
\begin{equation}
    p(\Tilde{x}|x) = N(\Tilde{x}; \alpha x, \sigma^2),
\end{equation}
where $\epsilon\sim N(0,1)$ and 
\begin{equation}
    N(\Tilde{x};\alpha x, \sigma^2) = C e^{-\frac{\|\Tilde{x}-\alpha x\|^2}{2\sigma^2}}.
\end{equation}
And 
\begin{equation}
    \epsilon = \frac{\Tilde{x}-\alpha x}{\sigma}.
\end{equation}\\[1em]

Questions arise: how can we get $x$ given $\Tilde{x}$?
\end{frame}

\begin{frame}{Tweedie's Formula}
    Tweedie's Formula (Bayes statistics) states (Robbins, 1956)
    \begin{theorem}
        Given random variables $x, y$, $y\sim N(x, \sigma^2I)$, i.e., $p(y|x) = N(x, \sigma^2)$, the expectation of $x$ could be given by 
        \begin{equation}
            \mathbb{E}[x|y] = y +\textcolor{red}{\sigma^2}\nabla \log p(y).
        \end{equation}
    \end{theorem}

Let
\begin{equation}
   x \leftarrow \alpha x, \quad y \leftarrow \Tilde{x},
\end{equation}
we have 
\begin{equation}
    s\equiv \nabla_{\Tilde{x}} \log p(\Tilde{x}) = -\frac{\Tilde{x}-\alpha \mathbb{E}[x|\Tilde{x}]}{\sigma^2}= -\frac{1}{\sigma}\mathbb{E}[\frac{\Tilde{x}-\alpha x}{\sigma}|\Tilde{x}] = -\frac{\mathbb{E}[\epsilon|\Tilde{x}]}{\sigma},
\end{equation}
where we have used the fact
$\epsilon = \frac{\Tilde{x}-\alpha x}{\sigma}.$

\end{frame}

\begin{frame}{Another insight: from the definition of the score $S$}
    Recall that adding noise by
    $\Tilde{x} = \alpha x + \sigma \epsilon$,
\begin{equation}\label{eq.cond}
    p(\Tilde{x}|x) = Ce^{-\frac{-\|\Tilde{x}-\alpha x\|^2}{2\sigma^2}}.
\end{equation}
Hence
\begin{equation}
    s(\Tilde{x}) = \nabla_{\Tilde{x}}\log p(\Tilde{x}) = \frac{\nabla_{\Tilde{x}}p(\Tilde{x})}{p(\Tilde{x})}=\frac{\int_x \nabla_{\Tilde{x}}p(\Tilde{x}|x) p(x)dx}{p(\Tilde{x})},
\end{equation}
From Eq. \eqref{eq.cond}, we have
\begin{equation}
s(\Tilde{x}) = \frac{\int_x \nabla_{\Tilde{x}} p(\Tilde{x}|x)p(\Tilde{x}|x) p(x)dx}{p(\Tilde{x})} = \int_x \nabla_{\Tilde{x}} \log p(\Tilde{x}|x)p(x|\Tilde{x})dx, 
\end{equation}
leading to
\begin{equation}
s(\Tilde{x}) = \mathbb{E}_x[\nabla_{\Tilde{x}} \log p(\Tilde{x}|x)| \Tilde{x}]=\mathbb{E}_x[-\frac{\Tilde{x}-\alpha x}{\sigma^2}| \Tilde{x}] = -\frac{\Tilde{x}-\alpha \mathbb{E}[x|\Tilde{x}]}{\sigma^2}.
\end{equation}
\end{frame}

\begin{frame}{Theoretical Support}
\begin{theorem}
\label{thm:conditional_expect}
    Let $X$ be an integrable random variable. Then for each $\sigma$-algebra $\mathcal{V}$ and $Y \in \mathcal{V}$, $Z = \mathbb{E}(X| \mathcal{V})$ solves the least square problem %\cite{evans2012introduction}
    $$\|Z - X\| = \min_{Y\in \mathcal{V}} \| Y - X\|\,,$$
    where $\| Y\| = \left( \int Y^2 dP \right)^{\frac{1}{2}}$.
\end{theorem}

\begin{lemma}
If $Y$ is $\mathcal{V}$-measurable, and $f$ is a measurable function in the sense that its domain and codomain are appropriately aligned with the $\sigma$-algebras, then $f(Y)$ will also be $\mathcal{V}$-measurable %\cite{evans2018measure}.
\end{lemma}

By Theorem \ref{thm:conditional_expect}, the score matching loss can be written as 
\begin{equation}
    \begin{aligned}
        Loss_{score} = \mathbb{E}_{t} \mathbb{E}_{x_t\sim p(x_t | x_0)}\mathbb{E}_{x_0} \| S_{\theta}(x_t, t) - \nabla_{\Tilde{x}} \log p(\Tilde{x}|x)\|^2\,.
    \end{aligned}
\end{equation}
\end{frame}

\begin{frame}{Revisit several models}
\begin{enumerate}
    \item Score model 
    \begin{equation}
        Loss_{score} = \|s_\theta(\Tilde{x}) - \frac{\epsilon}{\sigma}\|^2;
    \end{equation}
    \item $X$ prediction model ( denoising model, $x0$ model)
    \begin{equation}
        Loss_{x_0} = \|x_\theta (\Tilde{x})-x\|^2,
    \end{equation}
    with 
    \begin{equation}
        s(\Tilde{x}) = -\frac{\Tilde{x}-\alpha x_{\theta^*} (\Tilde{x})}{\sigma^2}
    \end{equation}
    where $x_\theta(\Tilde{x}) \to x_{\theta^*}(\Tilde{x})\equiv \mathbb{E}[x|\Tilde{x}]$;
    \item $\epsilon$ prediction model
    \begin{equation}
        Loss_{\epsilon} = \|\epsilon_\theta(\Tilde{x})-\epsilon\|^2,
    \end{equation}
    with
    \begin{equation}
        s(\Tilde{x}) = -\frac{\epsilon_{\theta^*}(\Tilde{x})}{\sigma},
    \end{equation}
    where $\epsilon_\theta(\Tilde{x})\to\epsilon_{\theta^*}(\Tilde{x})\equiv\mathbb{E}[\epsilon|\Tilde{x}]$.
\end{enumerate}
\end{frame}

\begin{frame}{The consistency of the three modeling}

As stated before, we have the following connection in the optimal $(\theta^*)$ case
\begin{equation}
    s_\theta^{*}(\Tilde{x}) = -\frac{\Tilde{x}-\alpha x_{\theta^*} (\Tilde{x})}{\sigma^2} =  -\frac{\epsilon_{\theta^*}(\Tilde{x})}{\sigma},
\end{equation}
by the above conditional expectation. 

Hence, in the real modeling of designing the loss, we use the connection of three models without reaching the optimal parameter
\begin{equation}
    s_\theta(\Tilde{x}) = -\frac{\Tilde{x}-\alpha x_{\theta} (\Tilde{x})}{\sigma^2} =  -\frac{\epsilon_{\theta}(\Tilde{x})}{\sigma},
\end{equation}
and substitute each other form to the loss definition above, we can recover all of the losses given by different models.
\end{frame}

\section{Diffusion model: from theories to implementation}
\begin{frame}{SMLD}
    Score Matching Langevin Dynamic (SMLD) (Song, 2019) adding noise in a following manner
    \begin{equation}
        p(\Tilde{x}_i| x) = N(\Tilde{x}_i; x, \sigma_i^2)\equiv Ce^{-\frac{\|\Tilde{x}_i-x\|^2}{2\sigma_i^2}},
    \end{equation}
    where a geometric sequence $\sigma_1> \sigma_2>\cdots > \sigma_T \approx
    0$ is given to add noise with different level.

    In a random variable view, 
    \begin{equation}
        \Tilde{x}_i = x + \sigma_i \epsilon
    \end{equation}
    for different $\sigma_i$ to get different noised random variable $\Tilde{x}_i$.

    Training object $J_{DSM}$ is given by 
    \begin{equation}
        J_{DSM} = \frac{1}{2}\mathbb{E}_{\sigma_i}\mathbb{E}_{p(x)}\mathbb{E}_{p(\Tilde{x}_i|x)}\left[\|s_\theta(\Tilde{x}_i,\sigma_i)+\frac{\Tilde{x}_i-x}{\sigma_i^2}\|^2\right].
    \end{equation}

    Anneled Langevin MCMC for sampling 
    \begin{equation}
        x_t = x_{t-1} + \frac{\Delta t}{2}S_\theta(x_{t-1}) + \sqrt{\Delta t}\epsilon, \quad \epsilon\sim N(0,1).
    \end{equation}
\end{frame}

\begin{frame}{DDPM}
    denoising diffusion probabilistic models (DDPM) (Ho, 2020) 
    \begin{enumerate}
        \item Derived from the Evidence Lower BOund (ELBO), \textcolor{red}{Not} score matching.
        \item First provide adding noise and denoise in the forward and reverse process. 
    \end{enumerate} 

The main procedure
\begin{enumerate}
    \item Adding noise 
    \begin{equation}
        x_t = \sqrt{1-\beta_t}x_{t-1} +\sqrt{\beta_t}\epsilon;
    \end{equation}
    \item Transition kernel 
    \begin{equation}
        p(x_t|x_0) = N(x_t;\alpha_t x_0, \sigma_t^2),
    \end{equation}
    where $\alpha_t = \prod_{i=1}^T \sqrt{1-\beta_t}$ and $\sigma_t^2 = 1-\alpha_t$.
\end{enumerate}
\end{frame}

\begin{frame}{DDPM}
The main procedure (Continued)
\begin{enumerate}
    \item Adding noise 
    \begin{equation}
        x_t = \sqrt{1-\beta_t}x_{t-1} +\sqrt{\beta_t}\epsilon;
    \end{equation}
    \item Transition kernel 
    \begin{equation}
        p(x_t|x_0) = N(x_t;\alpha_t x_0, \sigma_t^2), \text{ i.e., } x_t = \alpha_t x_0 + \sigma_t \epsilon,
    \end{equation}
    where $\alpha_t = \prod_{i=1}^T \sqrt{1-\beta_t}$ and $\sigma_t^2 = 1-\alpha_t$.
    \item Training Losss
    \begin{equation}
        \mathbb{E}_{t\sim U[0,1]}\mathbb{E}_{p(x)}\mathbb{E}_{p(x_t|x)}\left[\|\epsilon_\theta(x_t,t)-\epsilon\|^2\right],
    \end{equation}
    where we have used the approximation
        $x_0 = \frac{x_t-\sigma_t\epsilon}{\alpha_t}$.
    \\[-1em]
    \item Sampling 
    \begin{equation}
        x_{t-1} = \frac{1}{\sqrt{1-\beta_t}}(x_t+\beta_t s_\theta(x_t, t)) +\sqrt{\beta_t}\epsilon_t, \quad t = T, T-1, \cdots, 1.
    \end{equation}
\end{enumerate}
\end{frame}


\section{Continuous version of Diffusion Model}

\begin{frame}{The continuous version of SMLD}
Recall that
\begin{equation}
    x_t = x_0 + \sigma_t\epsilon,
\end{equation}
we can prove that 
\begin{equation}
    x_t = x_{t-1} + \sqrt{\sigma_t^2-\sigma_{t-1}^2}\epsilon.
\end{equation}
\begin{proof}
    We can prove the formula by a Recurrence 
    \begin{equation}
    \begin{aligned}
        x_t &= x_{t-1} + \sqrt{\sigma_t^2-\sigma_{t-1}^2}\epsilon\\
        & = x_{t-2} + \sqrt{\sigma_{t-1}^2-\sigma_{t-2}^2}\epsilon +\sqrt{\sigma_t^2-\sigma_{t-1}^2}\epsilon\\
        & = x_{t-2} + \sqrt{\sigma_t^2-\sigma_{t-2}^2}\epsilon\\
        & = ...= x_0 + \sigma_t\epsilon, \quad \text{ where } \sigma_0\approx 0.
    \end{aligned}
    \end{equation}
\end{proof}
\end{frame}

\begin{frame}{The continuous version of SMLD}
From 
\begin{equation}
    x_t = x_{t-1} + \sqrt{\sigma_t^2-\sigma_{t-1}^2}\epsilon,
\end{equation}
we have 
\begin{equation}
    \begin{aligned}
        \Delta x_t &= \sqrt{\frac{\sigma_t^2-\sigma_{t-1}^2}{\Delta t}}\sqrt{\Delta t}\epsilon\\
        &= \sqrt{\frac{\sigma_t^2-\sigma_{t-1}^2}{\Delta t}}\Delta B_t.
    \end{aligned}
\end{equation}
Further, let $\Delta t\to 0$, we have
\begin{equation}
    dx = \sqrt{\frac{d\sigma_t^2}{d t}}dB_t.
\end{equation}
\end{frame}

\begin{frame}{The continuous version of DDPM}
Recall that 
\begin{equation}
        x_t = \sqrt{1-\beta_t}x_{t-1} +\sqrt{\beta_t}\epsilon.
\end{equation}
Similarly 
\begin{equation}
    \begin{aligned}
        x_t\approx (1-\frac{1}{2}\beta_t)x_{t-1} + \sqrt{\beta_t}\epsilon,
    \end{aligned}
\end{equation}
hence, we have
\begin{equation}
    \begin{aligned}
        \Delta x_t &= -\frac{1}{2}\Tilde{\beta_t} x_{t-1}\Delta t + \sqrt{\Tilde{\beta_t}}\sqrt{\Delta t}\epsilon, \quad \text{ where } \Tilde{\beta_t} = \frac{\beta_i}{\Delta t}\\
        & = -\frac{1}{2}\Tilde{\beta_t} x_{t-1}\Delta t + \sqrt{\Tilde{\beta_t}}\Delta B_t.
    \end{aligned}
\end{equation}
Further, let $\Delta t\to 0$, we finally obtain
\begin{equation}
    dx = -\frac{1}{2}\Tilde{\beta_t} x d t + \sqrt{\Tilde{\beta_t}}d B_t.
\end{equation}
\end{frame}

\begin{frame}{VE \& VP}
Summarizing the form of continuous DDPM and SMLD, we summarize the adding noise process as
\begin{equation}\label{eq.forward}
    dx = f(x, t)dt + g(t) dB_t,
\end{equation}
where the corresponding distribution $p(x, t)$ satisfying the following Fokker-Planck equation
\begin{equation}\label{eq.fp}
    \frac{\partial p(x,t)}{\partial t} + \nabla\cdot\left(f(x,t) p(x,t)\right) -\frac{1}{2}g^2(t) \triangle p(x,t)=0.
\end{equation}

Training DSM object 
\begin{equation}
    J_{DSM} = \mathbb{E}_{t\sim U[0,1]}\mathbb{E}_{p(x_0)}\mathbb{E}_{p(x_t|x_0)}\left[\|s_\theta(x_t,t)-\textcolor{red}{\nabla_{x_t}\log p(x_t|x_0)}\|^2\right].
\end{equation}
\end{frame}


\begin{frame}{VE \& VP adding noise}
To training the Denoising Score Match loss $J_{DSM}$ above, the key is to add noise by the transition kernel
\begin{equation}
    p(\Tilde{x}|x) \equiv p(x(t)|x(0)) = N(x(t); \Tilde{\alpha}_t x(0), \Tilde{\sigma}_t^2),
\end{equation}
from which we can obtain the noised data 
\begin{equation}
    x(t) = \Tilde{\alpha}_t x(0) + \Tilde{\sigma}_t\epsilon, \quad \epsilon\sim N(0,1).
\end{equation}

\textcolor{red}{The question becomes}: Given VE \& VP 
\begin{equation}
    dx = \sqrt{\frac{d[\sigma^2]}{dt}} dB_t,\quad 
    dx = -\frac{1}{2}\Tilde{\beta_t} x d t + \sqrt{\Tilde{\beta_t}}d B_t.
\end{equation}
how to derive $p(x(t)|x(0))$, i.e., $p(\Tilde{x}|x)$ for adding noise?
\end{frame}

\begin{frame}{VE \& VP Transition kernel}
The summarizing form of VE \& VP is 
\begin{equation}
    dx = h(t)xdt+ g(t)dB_t,
\end{equation}
where $h(t)=0$ for VE and $h(t)=-\frac{1}{2}\Tilde{\beta}(t)$ for VP. 

\begin{lemma}
Let $\mu(t) =\mathbb{E}[x(t)]$ and $\Sigma(t)=\mathbb{E}\left[(x-\mu(t))(x-\mu(t))^T\right]$, we have the following formula
\begin{equation}
\begin{aligned}
    \frac{d\mu(t)}{dt} = h(t)\mu(t),\quad
    \frac{d\Sigma(t)}{dt} = 2h(t)\Sigma(t)+g^2(t)I.
\end{aligned} 
\end{equation}
\end{lemma}
The proof of the Lemma can be found in a stochastic differential equation textbook such as Applied Stochastic Differential Equations, S\"{a}rkk\"{a} and Solin, 2019.
\end{frame}

\begin{frame}{VE \& VP Transition kernel}

\begin{lemma}
    For VE, the transition kernel is given by the following formula
\begin{equation}\label{eq.tranve}
    P(x(t)|x(0)) = N(x(t); x(0), \sigma^2(t)-\sigma^2(0)).
\end{equation}
For VE, 
\begin{equation}
    \Tilde{\alpha}_t \equiv  1, \quad \Tilde{\sigma}^2_t \equiv \sigma^2(t)-\sigma^2(0)\approx \sigma^2(t).
\end{equation}
\end{lemma}

\begin{lemma}
    For VP, the transition kernel is given the following formula
\begin{equation}\label{eq.tranvp}
    p(x(t)|x(0)) = N\left(x(t); x(0)e^{-\frac{1}{2}\int_0^t \Tilde{\beta}(s)ds},1-e^{-\int_0^t \Tilde{\beta}(s)ds}\right).
\end{equation}
For VP, 
\begin{equation}
    \Tilde{\alpha}_t \equiv  e^{-\frac{1}{2}\int_0^t \Tilde{\beta}(s)ds}, \quad \Tilde{\sigma}^2_t \equiv 1-e^{-\int_0^t \Tilde{\beta}(s)ds}.
\end{equation}
\end{lemma}
\end{frame}


\begin{frame}{Proof of VE transition kernel}
\begin{proof}
For VE, by a simple calculation we have

\begin{equation}
        \frac{d\mu(t)}{dt} = 0,\quad \frac{d\Sigma(t)}{dt} = \frac{d[\sigma^2(t)]}{dt},
\end{equation}
Hence, it is easy to obtain the following form 
\begin{equation}
        \mu(t) = \mu(0) = x(0),\quad \Sigma(t) = \sigma^2(t)-\sigma^2(0).
\end{equation}
Here we have used the fact  
\begin{equation}
    \mu(0) = x(0), \quad \Sigma(0)=0
\end{equation}
as $x(0)$ is taken as a constant, not a random variable.
And we obtain 
\begin{equation}\label{eq.tranve}
    P(x(t)|x(0)) = N(x(t); x(0), \sigma^2(t)-\sigma^2(0)).
\end{equation}
\end{proof}
\end{frame}

\begin{frame}{Proof of VP transition kernel}
\scriptsize
\begin{proof}
For VP, by a simple calculation we have

\begin{equation}
        \frac{d\mu(t)}{dt} = -\frac{1}{2}\beta(t)\mu(t),\quad \frac{d\Sigma(t)}{dt} = -\beta(t)\Sigma(t)+\beta(t).
\end{equation}

Multiply the exponential term on the both sides, we have
\begin{equation}
\begin{aligned}
    &\frac{d\mu(t)}{dt}e^{\int_0^t\frac{1}{2}\beta(s)ds} + \frac{1}{2}\beta(t)\mu(t) e^{\int_0^t\frac{1}{2}\beta(s)ds} =0,\\ 
    &\frac{d\Sigma(t)}{dt}e^{\int_0^t\beta(s)ds} +\beta(t)\Sigma(t)e^{\int_0^t\beta(s)ds} = \beta(t)e^{\int_0^t\beta(s)ds}.
\end{aligned}
\end{equation}

Hence, we have the following form
\begin{equation}
    \frac{d}{dt} (\mu(t)e^{\int_0^t\frac{1}{2}\beta(s)ds}) = 0,\quad
    \frac{d}{dt} (\Sigma(t)e^{\int_0^t\beta(s)ds}) = \frac{d}{dt} e^{\int_0^t\beta(s)ds}.
\end{equation}
By a direct calculation, we can obtain
\begin{equation}\label{eq.tranvp}
    p(x(t)|x(0)) = N\left(x(t); x(0)e^{-\frac{1}{2}\int_0^t \beta(s)ds},1-e^{-\int_0^t \beta(s)ds}\right).
\end{equation}
\end{proof}
\end{frame}

\begin{frame}{Revisit adding noise}
The \textbf{equivalence} of the adding noise
\begin{enumerate}
    \item From the stochastic process, denote the variable $x_t$, we have 
    \begin{equation}
        d x_t = f(x,t)dt + g(t)dt, 
    \end{equation}
    with corresponding discrete form (Eular-Maruyama scheme)
    \begin{equation}
        x_{t+\Delta t} = x_{t} + f(x_t, t)\Delta t + g(t)\sqrt{\Delta t}\epsilon, \quad \epsilon\sim N(0, 1). 
    \end{equation}
\item From transition kernel perspective, 
\begin{equation}
    p(x_t) = \int_{x_0} p(x_0)p(x_t|x_0)dx_0,
\end{equation}
where 
\begin{equation}
    p(x_t|x_0) = N(x_t; \mu_t, \Sigma_t)=N(x_t; \Tilde{\alpha}_tx_0, \Tilde{\sigma}_t^2)=\frac{1}{C}e^{-\frac{\|x_t-\mu_t\|^2}{2\Sigma_t}}.
\end{equation}
\end{enumerate}

\end{frame}

\begin{frame}{Training recipe}
The training for VE follows the following process (VP is in a similar way)
\begin{enumerate}
    \item Random choose one data $x\sim p_{data}$;
    \item Random sample $t\sim U[0, 1]$;
    \item Random sample a white noise $\epsilon\sim N(0, 1)$;
    \item Adding noise 
    \begin{equation}
        x_t = \Tilde{\alpha}_t x + \Tilde{\sigma}_t\epsilon, 
    \end{equation}
    where the mean value $\Tilde{\alpha}_t x= x(0)$  and standard deviation $\Tilde{\sigma}_t = \sqrt{\sigma^2(t)-\sigma^2(0)}\approx \sigma(t)$ in VE referring to \eqref{eq.tranve}. VP is similar with the mean and standard deviation from its transition kernel \eqref{eq.tranvp};
    \item Compute the Loss
    by summation the following norm over $x$, $t$ and $\epsilon$ 
    \begin{equation}  
    \|s_\theta(x_t, t)-\epsilon/\Tilde{\sigma}_t\|.
    \end{equation} 
\end{enumerate}
\end{frame}


\begin{frame}{Inference: Reverse denoising process}
The reverse denoising process is given by 
\begin{equation}\label{eq.reverse}
    dx = (f(x,t)-g^2\nabla_x \log p(x,t))dt + g(t)dB_t,
\end{equation}
or 
\begin{equation}
    dx = (f(x,t)-\frac{1}{2}g^2\nabla_x \log p(x,t))dt,
\end{equation}
or 
\begin{equation}\label{eq.reverse2}
    dx = (f(x,t)-\frac{3}{2}g^2\nabla_x \log p(x,t))dt + \sqrt{2}g(t)dB_t,
\end{equation}
\begin{equation}
    \cdots
\end{equation}
Due to obeying the same Fokker-Planck equation for $p(x, t)$
\begin{equation}
    \frac{\partial p(x,t)}{\partial t} + \nabla\cdot(f(x,t) p(x,t)) -\frac{1}{2}g^2(t) \triangle p(x,t)=0.
\end{equation}
\end{frame}

\begin{frame}{Inference: Reverse denoising process (proof)}
In this slide, we only prove the first reverse sampling form \eqref{eq.reverse} and other cases can be done in a similar approach. 

\scriptsize
\begin{proof}
    The Fokker-Planck equation of the forward process \eqref{eq.forward} is given by \eqref{eq.fp} as
    \begin{equation}
        \frac{\partial p}{\partial t} + \nabla \cdot (f(x,t)p)-\frac{1}{2}g^2\triangle p = 0.
    \end{equation}
    Let $t = T-\tau$, we have
    \begin{equation}
        \frac{\partial p}{\partial \tau} - \nabla\cdot (f(x,T-\tau) p) + g^2\triangle p -\frac{1}{2}g^2\triangle p =0.
    \end{equation}
    By $\nabla\cdot\nabla = \triangle$ and $\nabla \log p=\nabla p/p$,
    we have
    \begin{equation}
        \frac{\partial p}{\partial \tau} - \nabla\cdot \bigg(\left(f(x,T-\tau)-g^2\nabla\log p\right)p\bigg) -\frac{1}{2}g^2\triangle p =0.
    \end{equation}
    Hence, we obtain the corresponding SDE form $dx = -(f(x, T-\tau)-g^2\nabla\log p)d\tau + gdB_\tau$.
    By a substitution $\tau = T-t$, we finally get $dx = (f(x,t)-g^2\nabla\log p)dt + gdB_t$.
\end{proof}
\end{frame}

% \begin{frame}{Interesting property about the ODE and SDE}
% \begin{enumerate}
%     \item The forward SDE and the reverse SDE has different sign 
% \end{enumerate}
% \end{frame}

\begin{frame}{Inference recipe}
The inference for VE follows the following process (VP is in a similar way)
\begin{enumerate}
    \item Random generate a noise at time $t=1$ as $x(1)\sim N(0, \sigma^2_{max})$;
    \item Integrate the reverse sampling equation 
    \begin{equation}
        dx = \left(f(x,t)-g^2(t) s_\theta(x,t)\right)dt + g(t)dB_t
    \end{equation} or 
    \begin{equation}
        dx = (f-\frac{1}{2}g^2 s_\theta)dt
    \end{equation}
    over the time span $[0, 1]$ to get $x(0)$.
    \item Corrector process: at each internal value $x(t)$, we can relax the value $x(t)$ by a corrector, which takes the Langevin MCMC process. 
\end{enumerate}

\end{frame}


\begin{frame}{The Corrector: revisit Langevin MCMC}
The Langevin diffusion process is given by 
\begin{equation}
    x_i = x_{i-1}+\frac{\Delta t}{2}\textcolor{red}{\nabla_x\log p(x_{i-1})}+\sqrt{\Delta t}\epsilon, \quad \epsilon\sim N(0, 1).
\end{equation}
We can prove   $\pi(x)$ of the obtained data points $\{x_i\}_{i=1}^N$ converges to $p(x)$.

\begin{proofs}
\scriptsize
The continuous form of above scheme is given by 
\begin{equation}
    dx = \frac{1}{2}\nabla\log p(x) dt + dB_t.
\end{equation}
The corresponding Fokker-Planck equation is written as
\begin{equation}
\frac{\partial\pi(x,t)}{\partial t} + \nabla\cdot(\frac{1}{2}\nabla\log p(x) \pi(x,t)) -\frac{1}{2}\triangle \pi(x,t) = 0.
\end{equation}
With a enough long time evolution, the distribution converges to a stable distribution where
\begin{equation}
    \frac{\partial \pi(x,t)}{\partial t} = 0, \quad t\to \infty.
\end{equation}
\end{proofs}
\end{frame}

\begin{frame}{The Corrector: revisit Langevin MCMC}

\begin{proofs}[\proofname\ (Cont)]
\scriptsize
Hence we have 
\begin{equation}
    \nabla\cdot(\pi\nabla\log p - \nabla\pi) = 0, \quad \forall x.
\end{equation}
Therefore, we have 
\begin{equation}
    \nabla\log p = \nabla\log \pi,
\end{equation}
given that $\pi>0$ almost true. 
Hence we have 
\begin{equation}
    \pi^*(x) = p(x).
\end{equation}
where $\pi^*$ is the stable distribution of $\pi(x, t)$.
\end{proofs}
\end{frame}

\section{Known and unkown questions}
\begin{frame}{Questions}
If you are interested in the questions, please feel free to write an email to me {\color{red}(\hyperlink{pisquare@microsoft.com}{pisquare@microsoft.com})} with your comments. 
\begin{enumerate}[(1.)]
    \item Please prove that the forms \eqref{eq.reverse}-\eqref{eq.reverse2} are equivalent with same marginal distribution $p(x,t)$ given the same initial condition;
    \item Please prove that the score function $s(x,t)$ satisfying the following formula
    \begin{equation}
        \frac{\partial s}{\partial t} = \nabla (-\nabla\cdot f - \langle f, s\rangle + \frac{1}{2}g^2\|s\|^2 + \frac{1}{2}g^2\langle \nabla, s \rangle);
    \end{equation}
    \item Why ISM loss is not commonly used like DSM loss in the diffusion model nowadays? Please make your comments.
\end{enumerate}
\end{frame}

% Thank you slide  
\begin{frame}{Welcome inputs}  
  \centering  
  Any comments?
  \\[2em]
  Welcome your inputs!  
\end{frame}  
  
\end{document}  
